#!/usr/bin/env python
# coding: utf-8

# In[ ]:


sentence_list = []
with open("pku_training.txt", 'rb') as f:
    # æ¯æ¬¡è¯»å–ä¸€è¡Œæ•°æ®
    line = f.readline()
    while line:
        line = line.decode("gb18030", "ignore")
        # æ¯ä¸€è¡Œä¸ºä¸€ä¸ªæ®µè½ï¼ŒæŒ‰å¥å·å°†æ®µè½åˆ‡åˆ†æˆå¥å­
        sentence = line.split('ã€‚')
        sentence_list.extend(sentence)
        line = f.readline()
# æ‰“å°å‡ºæ•°æ®çš„å‰ 5 å¥
# for i in range(5):
#     print(sentence_list[i])
#     print('-'*100)
def get_tag(word):
    tags = []  # åˆ›å»ºä¸€ä¸ªç©ºåˆ—è¡¨ç”¨æ¥å­˜æ”¾æ ‡æ³¨æ•°æ®
    word_len = len(word)
    if word_len == 1:  # å¦‚æœæ˜¯å•å­—æˆè¯ï¼Œæ ‡è®°ä¸º S
        tags = ['S']
    elif word_len == 2:  # å¦‚æœè¯¥è¯ä»…æœ‰ä¸¤ä¸ªå­—ï¼Œåˆ™æ ‡è®°ä¸º B å’Œ E
        tags = ['B', 'E']
    else:
        tags.append('B')  # ç¬¬ä¸€ä¸ªå­—æ ‡è®°ä¸º B
        tags.extend(['M']*(len(word)-2))  # ä¸­é—´æ ‡è®°ä¸º M ï¼Œ
        tags.append('E')  # æœ€åä¸€ä¸ªæ ‡è®°ä¸º E
    return tags


# # æµ‹è¯•æ ‡æ³¨å‡½æ•°
# get_tag('åˆ˜å¾·å')
def pre_data(data):
    X = []  # åˆ›å»ºä¸€ä¸ªç©ºåˆ—è¡¨æ¥å­˜æ”¾æ¯ä¸ªä¸­æ–‡å¥å­
    y = []  # åˆ›å»ºä¸€ä¸ªç©ºåˆ—è¡¨æ¥å­˜æ”¾æ¯ä¸ªå¥å­æ ‡æ³¨ç»“æœ
    word_dict = []  # åˆ›å»ºä¸€ä¸ªç©ºåˆ—è¡¨æ¥å­˜æ”¾æ¯ä¸ªå¥å­çš„æ­£ç¡®åˆ†è¯ç»“æœ
    for sentence in data:
        sentence = sentence.strip()
        if not sentence:
            continue
        # å°†å¥å­æŒ‰ç©ºæ ¼è¿›è¡Œåˆ‡åˆ†ï¼Œå¾—åˆ°è¯
        words = sentence.split("  ")
        word_dict.append(words)
        sent = []  # ç”¨äºä¸´æ—¶å­˜æ”¾ä¸€ä¸ªä¸­æ–‡å¥å­
        tags = []  # ç”¨äºä¸´æ—¶å­˜æ”¾ä¸€ä¸ªå¥å­å¯¹åº”çš„æ ‡æ³¨
        for word in words:
            sent.extend(list(word))
            tags.extend(get_tag(word))  # è·å¾—æ ‡æ³¨ç»“æœ
        X.append(sent)
        y.append(tags)
    return X, y, word_dict
train_data = sentence_list[:-60]
test_data = sentence_list[-60:]
train_X, train_y, train_word_dict = pre_data(train_data)
test_X, test_y, test_word_dict = pre_data(test_data)

# print(train_X[0])
# print('-'*100)
# print(train_y[0])
# print('-'*100)
# print(train_word_dict[0])
# print('='*100)
# print(test_X[0])
# print('-'*100)
# print(test_y[0])
# print('-'*100)
# print(test_word_dict[0])

states = {'B', 'M', 'E', 'S'}

def para_init():
    init_mat = {}  # åˆå§‹çŠ¶æ€çŸ©é˜µ
    emit_mat = {}  # å‘å°„çŸ©é˜µ
    tran_mat = {}  # è½¬ç§»çŠ¶æ€çŸ©é˜µ
    state_count = {}  # ç”¨äºç»Ÿè®¡æ¯ä¸ªéšè—çŠ¶æ€ï¼ˆå³ B,M,E,Sï¼‰å‡ºç°çš„æ¬¡æ•°
    for state in states:
        tran_mat[state] = {}
        for state1 in states:
            tran_mat[state][state1] = 0.0  # åˆå§‹åŒ–è½¬ç§»çŠ¶æ€çŸ©é˜µ
        emit_mat[state] = {}  # åˆå§‹åŒ–å‘å°„çŸ©é˜µ
        init_mat[state] = 0.0  # åˆå§‹åŒ–åˆå§‹çŠ¶æ€çŸ©é˜µ
        state_count[state] = 0.0  # åˆå§‹åŒ–çŠ¶æ€è®¡æ•°å˜é‡
    return init_mat, emit_mat, tran_mat, state_count

import pandas as pd
init_mat, emit_mat, tran_mat, state_count = para_init()
# print(pd.DataFrame(init_mat, index=['init']))
# print('-'*100)
# print(pd.DataFrame(tran_mat).T)
# print('-'*100)
# print((pd.DataFrame(emit_mat)).T)

def count(train_X, train_y):
    """
    train_X: ä¸­æ–‡å¥å­
    train_Y: å¥å­å¯¹åº”çš„æ ‡æ³¨
    """
    # åˆå§‹åŒ–ä¸‰ä¸ªçŸ©é˜µ
    init_mat, emit_mat, tran_mat, state_count = para_init()
    sent_count = 0
    for j in range(len(train_X)):
        # æ¯æ¬¡å–ä¸€ä¸ªå¥å­è¿›è¡Œç»Ÿè®¡
        sentence = train_X[j]
        sent_state = train_y[j]
        for i in range(len(sent_state)):
            if i == 0:
                # ç»Ÿè®¡æ¯ä¸ªçŠ¶æ€ï¼ˆå³ B,M,E,Sï¼‰åœ¨æ¯ä¸ªå¥å­å¯¹åº”çš„æ ‡æ³¨åºåˆ—ä¸­ç¬¬ä¸€ä¸ªä½ç½®çš„æ¬¡æ•°
                init_mat[sent_state[i]] += 1
                # ç»Ÿè®¡æ¯ä¸ªéšè—çŠ¶æ€ï¼ˆå³ B,M,E,Sï¼‰åœ¨æ•´ä¸ªè®­ç»ƒæ ·æœ¬ä¸­å‡ºç°çš„æ¬¡æ•°
                state_count[sent_state[i]] += 1
                # ç»Ÿè®¡æœ‰å¤šå°‘ä¸ªå¥å­ã€‚
                sent_count += 1
            else:
                # ç»Ÿè®¡ä¸¤ä¸ªç›¸é‚»æ—¶åˆ»çš„ä¸åŒçŠ¶æ€ç»„åˆåŒæ—¶å‡ºç°çš„æ¬¡æ•°
                tran_mat[sent_state[i-1]][sent_state[i]] += 1
                state_count[sent_state[i]] += 1
                # ç»Ÿè®¡æ¯ä¸ªçŠ¶æ€å¯¹åº”äºæ¯ä¸ªæ–‡å­—çš„æ¬¡æ•°
                if sentence[i] not in emit_mat[sent_state[i]]:
                    emit_mat[sent_state[i]][sentence[i]] = 1
                else:
                    emit_mat[sent_state[i]][sentence[i]] += 1
    return init_mat, emit_mat, tran_mat, state_count, sent_count


init_mat, emit_mat, tran_mat, state_count, sent_count = count(train_X, train_y)
# print(pd.DataFrame(init_mat, index=['init']))
# print('-'*100)
# print(pd.DataFrame(tran_mat).T)
# print('-'*100)
# # éšæœºå– 6 ä¸ªè§‚æµ‹å­—
# print((pd.DataFrame(emit_mat)).iloc[94:100, :].T)

def get_prob(init_mat, emit_mat, tran_mat, state_count, sent_count):
    tran_prob_mat = {}  # çŠ¶æ€è½¬ç§»çŸ©é˜µ
    emit_prob_mat = {}  # å‘å°„çŸ©é˜µ
    init_prob_mat = {}  # åˆå§‹çŠ¶æ€çŸ©é˜µ
    # è®¡ç®—åˆå§‹çŠ¶æ€çŸ©é˜µ
    for state in init_mat:
        init_prob_mat[state] = float(
            init_mat[state]/sent_count)
    # è®¡ç®—çŠ¶æ€è½¬ç§»çŸ©é˜µ
    for state in tran_mat:
        tran_prob_mat[state] = {}
        for state1 in tran_mat[state]:
            tran_prob_mat[state][state1] = float(
                tran_mat[state][state1]/state_count[state])
    # è®¡ç®—å‘å°„çŸ©é˜µ
    for state in emit_mat:
        emit_prob_mat[state] = {}
        for word in emit_mat[state]:
            emit_prob_mat[state][word] = float(
                emit_mat[state][word]/state_count[state])

    return tran_prob_mat, emit_prob_mat, init_prob_mat


tran_prob_mat, emit_prob_mat, init_prob_mat = get_prob(
    init_mat, emit_mat, tran_mat, state_count, sent_count)
# print(pd.DataFrame(init_prob_mat, index=['init']))
# print('-'*100)
# print(pd.DataFrame(tran_prob_mat).T)
# print('-'*100)
# print((pd.DataFrame(emit_prob_mat)).iloc[94:100, :].T)


# print(pd.DataFrame(init_prob_mat, index=['init']))
# print('-'*100)
# print(pd.DataFrame(tran_prob_mat).T)
# print('-'*100)
# print((pd.DataFrame(emit_prob_mat)).loc[['æ˜', 'å¤©', 'è¦', 'ä¸‹', 'é›¨'], :].T)


def predict(sentence, tran_prob_mat, emit_prob_mat, init_prob_mat):
        tab = [{}]  # ç”¨äºå­˜æ”¾å¯¹åº”èŠ‚ç‚¹çš„ ğ›¿ å€¼
        path = {}   # ç”¨äºå­˜æ”¾å¯¹åº”èŠ‚ç‚¹æ‰€ç»è¿‡çš„æœ€ä¼˜è·¯å¾„
        # æ±‚å‡º T0 æ—¶åˆ»çš„ ğ›¿ å€¼
        for state in states:
            tab[0][state] = init_prob_mat.get(
                state) * emit_prob_mat[state].get(sentence[0], 0.000000001)
            path[state] = [state]
        for t in range(1, len(sentence)):
            tab.append({})  # åˆ›å»ºä¸€ä¸ªå…ƒç»„æ¥å­˜æ”¾ ğ›¿ å€¼å’Œå¯¹åº”çš„èŠ‚ç‚¹
            new_path = {}
            for state1 in states:
                # state1 ä¸ºåä¸€ä¸ªæ—¶åˆ»çš„çŠ¶æ€
                items = []
                for state2 in states:
                     # state2 ä¸ºå‰ä¸€ä¸ªæ—¶åˆ»çš„çŠ¶æ€
                    if tab[t - 1][state2] == 0:
                        continue
                    # è®¡ç®—ä¸Šä¸€ä¸ªæ—¶åˆ»çŠ¶æ€ state2 åˆ°å½“å‰æ—¶åˆ»çš„çŠ¶æ€ state1 çš„è½¬ç§»æ¦‚ç‡å€¼
                    tr_prob = tran_prob_mat[state2].get( 
                        state1, 0.000000001) * emit_prob_mat[state1].get(sentence[t], 0.0000001)
                    # è®¡ç®—å½“å‰çš„çŠ¶æ€ä¸º state1 æ—¶ç»è¿‡ä¸Šä¸€ä¸ªæ—¶åˆ»çŠ¶æ€ state2 çš„æ¦‚ç‡å€¼
                    prob = tab[t - 1][state2] * tr_prob
                    items.append((prob, state2))
                if not items:
                    items.append((0.000000001, 'S'))
                # æ±‚å‡ºæŸä¸ªæ—¶åˆ»çš„æ¯ä¸ªçŠ¶æ€èŠ‚ç‚¹å¯¹åº”çš„æœ€ä¼˜è·¯å¾„
                best = max(items)  # best: (prob, state)
                tab[t][state1] = best[0]
                new_path[state1] = path[best[1]] + [state1]
            path = new_path
        # å¯»æ‰¾æœ€åä¸€ä¸ªæ—¶åˆ»æœ€å¤§çš„ ğ›¿ å€¼ä»¥åŠæ‰€å¯¹åº”çš„èŠ‚ç‚¹ï¼ˆå³çŠ¶æ€ï¼‰ã€‚
        prob, state = max([(tab[len(sentence) - 1][state], state)
                           for state in states])
        return path[state]  # è¿”å›æœ€å¤§ ğ›¿ å€¼èŠ‚ç‚¹æ‰€å¯¹åº”çš„è·¯å¾„
    
sentence = "æ˜å¤©è¦ä¸‹é›¨"
# tag = predict(sentence, tran_prob_mat, emit_prob_mat, init_prob_mat)
# '  '.join(tag)

def cut_sent(sentence, tags):
    """
    sentence:å¥å­
    tags:æ ‡æ³¨
    """
    word_list = []  # å­˜æ”¾åˆ‡åˆ†ç»“æœ
    start = -1
    started = False

    if len(tags) != len(sentence):
        return None

    if tags[-1] not in {'S', 'E'}:
        if tags[-2] in {'S', 'E'}:  # å¦‚æœæœ€åä¸€ä¸ªæ²¡æœ‰æ ‡è®°ä¸º 'S', 'E'ï¼Œå¹¶ä¸”å€’æ•°
            tags[-1] = 'S'  # ç¬¬äºŒä¸ªæ ‡è®°ä¸º 'S','E'åˆ™å°†æœ€åä¸€ä¸ªæ ‡è®°ä¸º 'S'
        else:  # å¦‚æœæœ€åä¸€ä¸ªæ²¡æœ‰æ ‡è®°ä¸º 'S', 'E'ï¼Œå¹¶ä¸”å€’æ•°
            tags[-1] = 'E'  # ç¬¬äºŒä¸ªæ ‡è®°ä¸º 'B','M'åˆ™å°†æœ€åä¸€ä¸ªæ ‡è®°ä¸º 'E'
    for i in range(len(tags)):
        if tags[i] == 'S':
            if started:
                started = False
                word_list.append(''.join(sentence[start:i]))
            word_list.append(sentence[i])
        elif tags[i] == 'B':
            if started:
                word_list.append(''.join(sentence[start:i]))
            start = i
            started = True
        elif tags[i] == 'E':
            started = False
            word = sentence[start:i + 1]
            word_list.append(''.join(word))
        elif tags[i] == 'M':
            continue
    return word_list

# result = cut_sent(sentence, tag)
# ' | '.join(result)

def word_seg(sentence, tran_prob_mat, emit_prob_mat, init_prob_mat):
    tags = predict(sentence, tran_prob_mat, emit_prob_mat, init_prob_mat)
    result = cut_sent(sentence, tags)
    return result

# æµ‹è¯•å®šä¹‰çš„å‡½æ•°
# result = word_seg(sentence, tran_prob_mat, emit_prob_mat, init_prob_mat)
# ' | '.join(result)

# def accurency(y_pre, y):
#     """
#     åˆ†è¯å‡†ç¡®ç‡è®¡ç®—å‡½æ•°
#     y_preï¼šé¢„æµ‹ç»“æœ
#     y:     æ­£ç¡®ç»“æœ
#     """
#     count = 0
#     n = len(y_pre)
#     for i in range(len(y_pre)):
#         # ç»Ÿè®¡æ¯ä¸ªå¥å­åˆ‡åˆ†å‡ºæ¥çš„è¯æ•°
#         n += len(y_pre[i])
#         for word in y_pre[i]:
#             # ç»Ÿè®¡æ¯ä¸ªå¥å­åˆ‡è¯æ­£ç¡®çš„è¯æ•°
#             if word in y[i]:
#                 count += 1
#     return count/n

# from tqdm.notebook import tqdm

# word_cut_result = []  # åˆ›å»ºä¸€ä¸ªç©ºåˆ—è¡¨æ¥å­˜æ”¾åˆ†è¯ç»“æœ

# # æ¯æ¬¡åˆ‡ä¸€ä¸ªå¥å­
# for sent in tqdm(test_X):
#     # ä½¿ç”¨å‰é¢æ‰€æ„å»ºçš„åˆ†è¯å™¨è¿›è¡Œåˆ‡è¯
#     temp = word_seg(sent, tran_prob_mat, emit_prob_mat, init_prob_mat)
#     # å­˜æ”¾åˆ†è¯åçš„æ•°æ®
#     word_cut_result.append(temp)


# # è®¡ç®—å‡†ç¡®ç‡
# acc = accurency(word_cut_result, test_word_dict)
# acc

# print(' | '.join(word_cut_result[0]))
# print('-'*100)
# print(' | '.join(test_word_dict[0]))

# sentence = 'å®ç°è‡ªåˆ†å‰²åˆ†è¯æˆ–ç»“åˆç»Ÿè®¡æ¶ˆæ­§çš„åˆ†è¯ç®—æ³•æˆ–åŸºäºç¥ç»ç½‘ç»œçš„åˆ†è¯ç®—æ³•ï¼Œæˆ–å¯¹æœºæ¢°åˆ†è¯è¿›è¡Œå¾ˆå¥½çš„ä¼˜åŒ–'
# result = word_seg(sentence, tran_prob_mat, emit_prob_mat, init_prob_mat)
# ' | '.join(result)


# In[2]:

while True:
  sentence = input("è¯·è¾“å…¥åˆ†è¯è¯­å¥ï¼š\n")
  result = word_seg(sentence, tran_prob_mat, emit_prob_mat, init_prob_mat)
  a=' | '.join(result)

  print(a)
# input("Press <enter>")







